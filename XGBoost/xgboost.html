<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>What is XGBoost?</title>
    <meta name="theme-color" content="rgb(255,255,255)">
    <meta name="twitter:title" content="What is XGBoost?">
    <meta name="description" content="XGBoost is the leading model for working with standard tabular data (the type of data you store in Pandas DataFrames, as opposed to more exotic types of data like images and videos). XGBoost models dominate many Kaggle competitions.">
    <meta name="twitter:card" content="summary">
    <meta property="og:image" content="">
    <meta property="og:type" content="article">
    <meta name="twitter:description" content="XGBoost is the leading model for working with standard tabular data (the type of data you store in Pandas DataFrames, as opposed to more exotic types of data like images and videos). XGBoost models dominate many Kaggle competitions.">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="32x32" href="assets/img/favicon-32x32.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.4.1/css/bootstrap.min.css">
    <link rel="manifest" href="manifest.json">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alegreya">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Bitter">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Crete+Round">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="assets/css/styles.min.css">
</head>

<body>
    <nav class="navbar navbar-light navbar-expand-md sticky-top" id="navigation" style="padding: 25px 0px;background-color: white;">
        <div class="container-fluid container"><a class="navbar-brand" href="https://devincept.codes/" style="background-image: url(&quot;assets/img/CODES.gif&quot;);background-position: center;background-size: cover;background-repeat: no-repeat;width: 170px;height: 65px;"></a><button data-toggle="collapse" class="navbar-toggler"
                data-target="#navcol-1"><span class="sr-only">Toggle navigation</span><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse text-uppercase" id="navcol-1" style="font-family: Roboto, sans-serif;font-weight: bold;">
                <ul class="nav navbar-nav ml-auto" style="font-size: 11px;">
                    <li class="nav-item" role="presentation"><a class="nav-link active"
                            href="https://devincept.codes/contribute.html">Contribute</a></li>
                    <li class="nav-item" role="presentation"><a class="nav-link active" href="https://devincept.tech/pricing.html">Free
                            courses</a></li>
                    <li class="nav-item" role="presentation"><a class="nav-link" href="https://devincept.codes/sponsor.html">Sponsor us</a>
                </ul>
            </div>
        </div>
    </nav>
    <section id="hero" style="background-color: #2f1b1b;color: rgb(255,255,255);">
        <div style="padding: 30px;">
            <p class="d-flex justify-content-center" style="font-family: Belgrano, serif;">&nbsp;Machine Learning</p>
            <h1 class="d-flex justify-content-center topic-title" style="font-family: Belgrano, serif;">What is XGBoost?<br></h1>
        </div>
        <div id="base" style="background-color: rgba(255,255,255,0.1);padding: 10px 0;font-family: Belgrano, serif;">
            <p class="justify-content-center"><i class="fa fa-align-center"></i>&nbsp;&nbsp;<span id="visits">0</span>&nbsp;Reads</p>
        </div>
    </section>
    <section id="sidetab" style="margin-bottom: 0px;">
        <div class="container-fluid">
            <div class="row content-row">
                <div class="col-3 author">
                    <div class="author-details"><div>
    <div class="author">
        
        <h2 class="author-title"> Author's Details </h2>
        
        <h3 class="author's-name"> Vaibhav </h3>
      
        
    
    </div>
</div></div>
                </div>
                <div class="col-9 main-content">
                    <div class="content-inner"><div>
  <div class="blog-content">
        <h1 id="what-is-ensemble-learning-">What Is Ensemble Learning?</h1>
<p>Ensemble learning combines several base algorithms to form one optimized predictive algorithm. For example, a typical Decision Tree for classification takes several factors, turns them into rule questions, and given each factor, either makes a decision or considers another factor. The result of the decision tree can become ambiguous if there are multiple decision rules, e.g. if threshold to make a decision is unclear or we input new sub-factors for consideration. This is where Ensemble Methods comes at one&#39;s disposable. Instead of being hopeful on one Decision Tree to make the right call, Ensemble Methods take several different trees and aggregate them into one final, strong predictor.</p>
<h2 id="types-of-ensemble-methods">Types Of Ensemble Methods</h2>
<p>Ensemble Methods can be used for various reasons, mainly to:</p>
<pre><code>Decrease Variance (<span class="hljs-name">Bagging</span>)
Decrease Bias (<span class="hljs-name">Boosting</span>)
Improve Predictions (<span class="hljs-name">Stacking</span>)
</code></pre><h2 id="boosting-in-ensemble-methods">Boosting in Ensemble Methods</h2>
<p>Just as humans learn from their mistakes and try not to repeat them further in life, the Boosting algorithm tries to build a strong learner (predictive model) from the mistakes of several weaker models. You start by creating a model from the training data. Then, you create a second model from the previous one by trying to reduce the errors from the previous model. Models are added sequentially, each correcting its predecessor, until the training data is predicted perfectly or the maximum number of models have been added.</p>
<p>Boosting basically tries to reduce the bias error which arises when models are not able to identify relevant trends in the data. This happens by evaluating the difference between the predicted value and the actual value.</p>
<h3 id="types-of-boosting-algorithms">Types of Boosting Algorithms</h3>
<pre><code><span class="hljs-number">1</span><span class="hljs-selector-class">.AdaBoost</span> (Adaptive Boosting)
<span class="hljs-number">2</span><span class="hljs-selector-class">.Gradient</span> Tree Boosting
<span class="hljs-number">3</span>.XGBoost
</code></pre><h2 id="what-is-xgboost">What is XGBoost</h2>
<p>XGBoost is the leading model for working with standard tabular data (the type of data you store in Pandas DataFrames, as opposed to more exotic types of data like images and videos).       XGBoost models dominate many Kaggle competitions.</p>
<p>To reach peak accuracy, XGBoost models require more knowledge and model tuning than techniques like Random Forest. After this tutorial, you&#39;ill be able to</p>
<pre><code>Follow <span class="hljs-keyword">the</span> full modeling workflow <span class="hljs-keyword">with</span> XGBoost
Fine-tune XGBoost models <span class="hljs-keyword">for</span> optimal performance
</code></pre><p>XGBoost is an implementation of the Gradient Boosted Decision Trees algorithm (scikit-learn has another version of this algorithm, but XGBoost has some technical advantages.) What is Gradient Boosted Decision Trees? We&#39;ll walk through a diagram.</p>
<p><br/><img src="https://i.imgur.com/e7MIgXk.png" alt="What is XGBoost"><br/>
We go through cycles that repeatedly builds new models and combines them into an ensemble model. We start the cycle by calculating the errors for each observation in the dataset. We then build a new model to predict those. We add predictions from this error-predicting model to the &quot;ensemble of models.&quot;</p>
<p>To make a prediction, we add the predictions from all previous models. We can use these predictions to calculate new errors, build the next model, and add it to the ensemble.</p>
<p>There&#39;s one piece outside that cycle. We need some base prediction to start the cycle. In practice, the initial predictions can be pretty naive. Even if it&#39;s predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.</p>
<h2 id="xgboost-features">XGBoost Features</h2>
<p>The library is laser focused on computational speed and model performance, as such there are few frills. Nevertheless, it does offer a number of advanced features.</p>
<h3 id="model-features">Model Features</h3>
<p>The implementation of the model supports the features of the scikit-learn and R implementations, with new additions like regularization. Three main forms of gradient boosting are supported:</p>
<pre><code>Gradient Boosting algorithm also called gradient boosting machine including the learning rate.
Stochastic Gradient Boosting with<span class="hljs-built_in"> sub-sampling </span>at the row, column<span class="hljs-built_in"> and </span>column per split levels.
Regularized Gradient Boosting with both L1<span class="hljs-built_in"> and </span>L2 regularization.
</code></pre><h3 id="system-features">System Features</h3>
<p>The library provides a system for use in a range of computing environments, not least:</p>
<pre><code>Parallelization <span class="hljs-keyword">of</span> tree construction <span class="hljs-keyword">using</span> all <span class="hljs-keyword">of</span> your CPU cores during training.
Distributed Computing <span class="hljs-keyword">for</span> training very large models <span class="hljs-keyword">using</span> <span class="hljs-keyword">a</span> cluster <span class="hljs-keyword">of</span> machines.
Out-<span class="hljs-keyword">of</span>-Core Computing <span class="hljs-keyword">for</span> very large datasets that don’t fit <span class="hljs-keyword">into</span> memory.
Cache Optimization <span class="hljs-keyword">of</span> data structures <span class="hljs-keyword">and</span> algorithm <span class="hljs-built_in">to</span> make best use <span class="hljs-keyword">of</span> hardware.
</code></pre><h2 id="why-use-xgboost-">Why Use XGBoost?</h2>
<p>The two reasons to use XGBoost are also the two goals of the project:</p>
<pre><code>Execution Speed.
Model Performance.
</code></pre><p>XGBoost and Gradient Boosting Machines (GBMs) are both ensemble tree methods that apply the principle of boosting weak learners (CARTs generally) using the gradient descent architecture. However, XGBoost improves upon the base GBM framework through systems optimization and algorithmic enhancements.</p>
<p><br/><img src="https://miro.medium.com/max/875/1*FLshv-wVDfu-i54OqvZdHg.png" alt="What is XGBoost"><br/></p>

 
 <p class="ipynb-link">You can learn more about this topic from<a href="https://github.com/Learn-Write-Repeat/ml/blob/main/XGBoost/Vaibhav_ML_XGboost.ipynb">here</a>.</p>
 
   </div>


</div></div>
                </div>
            </div>
        </div>
    </section>
    <footer class="d-flex flex-column justify-content-center align-items-center" id="footer" style="padding-bottom: 0;">
        <h1>DevIncept.codes</h1>
        <h5>Contact us:</h5>
        <p>Email:<a href="#">&nbsp;support@devincept.tech</a></p>
        <div class="d-flex flex-row" id="social-button"><button class="btn btn-primary" type="button"><a href="https://www.linkedin.com/company/devincept/" target="_blank"><i class="fa fa-linkedin-square" style="font-size: 24px;" href=""></i></a></button><button class="btn btn-primary" type="button"><a href="https://www.facebook.com/DevIncept/" target="_blank"><i class="fa fa-facebook" style="font-size: 24px;"></i></a></button>
            <button
                class="btn btn-primary" type="button"><a href="https://www.instagram.com/devincept.tech/?hl=en" target="_blank"><i class="fa fa-instagram" style="font-size: 24px;"></i></a></button><button class="btn btn-primary" type="button"><a href="https://github.com/Learn-Write-Repeat" target="_blank"><i class="fa fa-github" style="font-size: 24px;"></i></a></button></div>
    </footer>
    <script>
        function cb(response) {
            document.getElementById('visits').innerText = response.value;
        }
    </script>
    <script async src="https://api.countapi.xyz/hit/ml-xgboost/visits?callback=cb"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.4.1/js/bootstrap.bundle.min.js"></script>
</body>

</html>